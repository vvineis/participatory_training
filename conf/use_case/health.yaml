name: health

data_path: "C:/Users/Vittoria/Documents/GitHub/participatory_training/data/health/ihdp_npci_1.csv"
result_path: "C:/Users/Vittoria/Documents/GitHub/participatory_training/results/health/"

criteria:
  ranking_criteria:
    Demographic Parity: zero
    Equal Opportunity: zero
    Equalized Odds: zero
    Calibration: zero
    Total Cost: min
    Accuracy: max

  metrics_for_evaluation:
    - Demographic Parity
    - Equal Opportunity
    - Equalized Odds
    - Calibration
    - Total Cost
    - Accuracy
  


  ranking_weights:
    Demographic Parity: 0.2
    Equal Opportunity: 0
    Equalized Odds: 0
    Calibration: 0.2
    Total Cost: 0.2
    Accuracy: 0.4

case_specific_metrics: 
  metrics: 
    - 'Total Cost'
    - 'Avg_outcome_score'

  case_specific_metrics_module: 
    _target_: utils.metrics.case_specific_metrics.HealthCaseMetrics
  
  positive_attribute_for_fairness: x7
  positive_group_value: 1
  threshold_outcome: np.median(data['y_factual'])

standard_metrics: 
  - Accuracy
  - Proportion Correct A Decisions
  - Proportion Correct C Decisions


reward_calculator:
  _target_: utils.rewards.get_rewards.HealthRewardCalculator
  reward_types: ${actors.reward_types}
  base_cost: {'1': 1, '0': 0}
  max_cost: 8400 
  alpha: 0.7

models:
  outcome: 
    model_type: causal_regression
    model_class: CausalOutcomeModel
    learner:
      _target_: xgboost.XGBRegressor
    param_grid:
        max_depth: [3, 5]
        n_estimators: [100, 200]
        
  rewards:
    regressor:
      _target_: sklearn.ensemble.RandomForestRegressor
      n_estimators: 100
      max_depth: 10
      random_state: 42  
    param_grid:
      n_estimators:
        - 50
        - 100
        - 150
      max_depth:
        - null
        - 10
        - 20


actions_outcomes:
  actions_set: 
    - 1
    - 0

  positive_actions_set:
    - 1

  outcomes_set: #binarized outcome set based on the threshold
   - 1
   - 0
  
  positive_outcomes_set:
    - 1

actors: 
  actor_list: 
    - Max_outcome
    - Min_cost
    - Balance
    - Outcome_Pred_Model

  reward_types: 
    - Max_outcome
    - Min_cost
    - Balance

augmentation_for_rewards:
  augmentation_parameters:
      actions_set: ${actions_outcomes.actions_set}
      additional_arguments: []

context:
  feature_columns:
    - x1
    - x2
    - x3
    - x4
    - x5
    - x6
    - x7
    - x8
    - x9
    - x10
    - x11
    - x12
    - x13
    - x14
    - x15
    - x16
    - x17
    - x18
    - x19
    - x20
    - x21
    - x22
    - x23
    - x24
    - x25


  columns_to_display:
    - x7



  